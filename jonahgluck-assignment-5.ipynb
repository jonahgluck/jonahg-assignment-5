{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d71bb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T22:15:09.524102Z",
     "iopub.status.busy": "2024-10-19T22:15:09.523376Z",
     "iopub.status.idle": "2024-10-19T22:18:54.926685Z",
     "shell.execute_reply": "2024-10-19T22:18:54.924551Z"
    },
    "papermill": {
     "duration": 225.412962,
     "end_time": "2024-10-19T22:18:54.929866",
     "exception": false,
     "start_time": "2024-10-19T22:15:09.516904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC score for k=3: 0.942572945292973\n",
      "Mean AUC score for k=5: 0.949471828003707\n",
      "Mean AUC score for k=7: 0.9521628150359847\n",
      "Mean AUC score for k=9: 0.9521915937782733\n",
      "Mean AUC score for k=11: 0.9513777560928247\n",
      "Best k value: 9 with AUC: 0.9521915937782733\n",
      "Submission file saved as 'submission.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter # for counting elements\n",
    "from numba import njit, prange # for increased speed precompiling code\n",
    "\n",
    "train_data = pd.read_csv('/kaggle/input/506-data/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/506-data/test.csv')\n",
    "\n",
    "features = ['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', \n",
    "            'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', \n",
    "            'EstimatedSalary']\n",
    "X = train_data[features]\n",
    "y = train_data['Exited']\n",
    "\n",
    "num_features = ['CreditScore', 'Age', 'Tenure', 'Balance', \n",
    "                'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "cat_features = ['Geography', 'Gender']\n",
    "\n",
    "class StandardScalerCustom:\n",
    "    def fit(self, X):\n",
    "        self.mean_ = np.mean(X, axis=0)\n",
    "        self.std_ = np.std(X, axis=0)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return (X - self.mean_) / self.std_\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "class OneHotEncoderCustom:\n",
    "    def fit(self, X):\n",
    "        self.categories_ = [np.unique(X[:, i]) for i in range(X.shape[1])]\n",
    "    \n",
    "    def transform(self, X):\n",
    "        one_hot_encoded = []\n",
    "        for i in range(X.shape[1]):\n",
    "            one_hot_col = np.zeros((X.shape[0], len(self.categories_[i])))\n",
    "            for j, category in enumerate(self.categories_[i]):\n",
    "                one_hot_col[:, j] = (X[:, i] == category).astype(float)\n",
    "            one_hot_encoded.append(one_hot_col)\n",
    "        return np.hstack(one_hot_encoded)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "class ColumnTransformerCustom:\n",
    "    def __init__(self, transformers):\n",
    "        self.transformers = transformers\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        transformed_columns = []\n",
    "        for name, transformer, columns in self.transformers:\n",
    "            X_subset = X[columns].values\n",
    "            transformed_columns.append(transformer.fit_transform(X_subset))\n",
    "        return np.hstack(transformed_columns)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        transformed_columns = []\n",
    "        for name, transformer, columns in self.transformers:\n",
    "            X_subset = X[columns].values\n",
    "            transformed_columns.append(transformer.transform(X_subset))\n",
    "        return np.hstack(transformed_columns)\n",
    "\n",
    "class StratifiedKFoldCustom:\n",
    "    def __init__(self, n_splits, shuffle=False, random_state=None):\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def split(self, X, y):\n",
    "        labels, counts = np.unique(y, return_counts=True)\n",
    "        folds = [[] for _ in range(self.n_splits)]\n",
    "        label_indices = {label: np.where(y == label)[0] for label in labels}\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.seed(self.random_state)\n",
    "            for label in labels:\n",
    "                np.random.shuffle(label_indices[label])\n",
    "        \n",
    "        for label in labels:\n",
    "            label_count = len(label_indices[label])\n",
    "            for fold_idx in range(self.n_splits):\n",
    "                start_idx = fold_idx * (label_count // self.n_splits)\n",
    "                end_idx = (fold_idx + 1) * (label_count // self.n_splits)\n",
    "                folds[fold_idx].extend(label_indices[label][start_idx:end_idx])\n",
    "                \n",
    "        for i in range(self.n_splits):\n",
    "            train_idx = np.hstack([folds[j] for j in range(self.n_splits) if j != i])\n",
    "            val_idx = np.array(folds[i])\n",
    "            yield train_idx, val_idx\n",
    "\n",
    "class SMOTECustom:\n",
    "    def __init__(self, random_state=None):\n",
    "        self.random_state = random_state\n",
    "        if random_state is not None:\n",
    "            np.random.seed(random_state)\n",
    "\n",
    "    def fit_resample(self, X, y):\n",
    "        counts = Counter(y)\n",
    "        max_class = max(counts, key=counts.get)\n",
    "        minority_class = min(counts, key=counts.get)\n",
    "\n",
    "        minority_idx = np.where(y == minority_class)[0]\n",
    "        majority_idx = np.where(y == max_class)[0]\n",
    "\n",
    "        n_samples_to_generate = len(majority_idx) - len(minority_idx)\n",
    "        synthetic_samples = []\n",
    "\n",
    "        while len(synthetic_samples) < n_samples_to_generate:\n",
    "            idx = np.random.choice(minority_idx)\n",
    "            # Find k nearest neighbors of the selected minority sample\n",
    "            distances = np.linalg.norm(X[minority_idx] - X[idx], axis=1)\n",
    "            nearest_neighbors_idx = np.argsort(distances)[1:]  # Exclude the sample itself\n",
    "\n",
    "            # Randomly select one of the nearest neighbors\n",
    "            neighbor_idx = np.random.choice(minority_idx[nearest_neighbors_idx])\n",
    "            diff = X[neighbor_idx] - X[idx]\n",
    "            new_sample = X[idx] + np.random.rand() * diff\n",
    "            synthetic_samples.append(new_sample)\n",
    "\n",
    "        X_resampled = np.vstack((X, synthetic_samples))\n",
    "        y_resampled = np.hstack((y, [minority_class] * len(synthetic_samples)))\n",
    "\n",
    "        return X_resampled, y_resampled\n",
    "\n",
    "def roc_auc_score_custom(y_true, y_score):\n",
    "    pos_label = 1\n",
    "    desc_score_indices = np.argsort(y_score)[::-1]\n",
    "    y_true = np.array(y_true)[desc_score_indices]\n",
    "    y_score = np.array(y_score)[desc_score_indices]\n",
    "    \n",
    "    distinct_value_indices = np.where(np.diff(y_score))[0]\n",
    "    threshold_idxs = np.r_[distinct_value_indices, y_true.size - 1]\n",
    "\n",
    "    tps = np.cumsum(y_true == pos_label)[threshold_idxs]\n",
    "    fps = 1 + threshold_idxs - tps\n",
    "    \n",
    "    tps = np.r_[0, tps]\n",
    "    fps = np.r_[0, fps]\n",
    "    \n",
    "    fpr = fps / fps[-1]\n",
    "    tpr = tps / tps[-1]\n",
    "    \n",
    "    return np.trapz(tpr, fpr)\n",
    "\n",
    "# KNN Algorithm\n",
    "@njit(parallel=True)\n",
    "def compute_distances(X_train, X_test):\n",
    "    n_train, n_test = X_train.shape[0], X_test.shape[0]\n",
    "    distances = np.empty((n_test, n_train))\n",
    "    for i in prange(n_test):\n",
    "        for j in range(n_train):\n",
    "            distances[i, j] = np.sqrt(np.sum((X_test[i] - X_train[j]) ** 2)) \n",
    "    return distances\n",
    "\n",
    "@njit(parallel=True)\n",
    "def knn_predict_proba(X_train, y_train, X_test, k):\n",
    "    distances = compute_distances(X_train, X_test)\n",
    "    n_test = X_test.shape[0]\n",
    "    y_prob = np.empty(n_test, dtype=np.float64)\n",
    "\n",
    "    for i in prange(n_test):\n",
    "        neighbors = np.argsort(distances[i])[:k] \n",
    "        top_k_labels = y_train[neighbors]\n",
    "        \n",
    "        y_prob[i] = np.sum(top_k_labels) / k \n",
    "\n",
    "    return y_prob\n",
    "\n",
    "preprocessor = ColumnTransformerCustom(\n",
    "    transformers=[\n",
    "        ('num', StandardScalerCustom(), num_features),\n",
    "        ('cat', OneHotEncoderCustom(), cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "smote = SMOTECustom(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_preprocessed, y)\n",
    "\n",
    "kf = StratifiedKFoldCustom(n_splits=5, shuffle=True, random_state=42)\n",
    "k_values = [3, 5, 7, 9, 11]\n",
    "\n",
    "best_k = 0\n",
    "best_auc = 0\n",
    "for k in k_values:\n",
    "    auc_scores = []\n",
    "    for train_index, val_index in kf.split(X_resampled, y_resampled):\n",
    "        X_train_fold, X_val_fold = X_resampled[train_index], X_resampled[val_index]\n",
    "        y_train_fold, y_val_fold = y_resampled[train_index], y_resampled[val_index]\n",
    "\n",
    "        y_val_prob_fold = knn_predict_proba(X_train_fold, y_train_fold, X_val_fold, k)\n",
    "        \n",
    "        auc_score_fold = roc_auc_score_custom(y_val_fold, y_val_prob_fold)\n",
    "        auc_scores.append(auc_score_fold)\n",
    "    \n",
    "    mean_auc_score = np.mean(auc_scores)\n",
    "    print(f'Mean AUC score for k={k}: {mean_auc_score}')\n",
    "    \n",
    "    if mean_auc_score > best_auc:\n",
    "        best_auc = mean_auc_score\n",
    "        best_k = k\n",
    "\n",
    "print(f'Best k value: {best_k} with AUC: {best_auc}')\n",
    "\n",
    "X_test = preprocessor.transform(test_data[features])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "y_test_probabilities = knn_predict_proba(X_resampled, y_resampled, X_test, best_k)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'Exited': y_test_probabilities \n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file saved as 'submission.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c490a498",
   "metadata": {
    "papermill": {
     "duration": 0.002507,
     "end_time": "2024-10-19T22:18:54.935667",
     "exception": false,
     "start_time": "2024-10-19T22:18:54.933160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5883045,
     "sourceId": 9635558,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 230.508861,
   "end_time": "2024-10-19T22:18:56.166256",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-19T22:15:05.657395",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
